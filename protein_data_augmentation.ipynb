{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "QToUCvADa4l7"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import roc_auc_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_proteins = pd.read_csv(\"protein_augmentation_datasets.csv\")\n",
        "\n",
        "\n",
        "# Excludes proteins which contain selenocysteine\n",
        "\n",
        "all_proteins = all_proteins[all_proteins['Sequence'].str.contains('U') == False]\n",
        "\n",
        "\n",
        "# Creates the separate task datasets\n",
        "\n",
        "tclin_set = all_proteins[['Sequence', 'Tclin']].copy().rename(\n",
        "    columns={\"Tclin\": \"Label\"})\n",
        "metal_ion_set = all_proteins[['Sequence', 'Metal ion binding']].copy().rename(\n",
        "    columns={\"Metal ion binding\": \"Label\"})\n",
        "pol_II_set = all_proteins[['Sequence', 'Pos reg RNA pol II']].copy().rename(\n",
        "    columns={\"Pos reg RNA pol II\": \"Label\"})\n",
        "colitis_set = all_proteins[['Sequence', 'Ulcerative colitis']].copy().rename(\n",
        "    columns={\"Ulcerative colitis\": \"Label\"})\n",
        "lc_set = all_proteins[['Sequence', 'Liver cancer']].copy().rename(\n",
        "    columns={\"Liver cancer\": \"Label\"})\n",
        "\n",
        "all_proteins"
      ],
      "metadata": {
        "id": "Ecm66Cwya_WU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "e9d7f3cb-7232-474f-95d9-66ca2578492f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      UniProt   Symbol                                           Sequence  \\\n",
              "0      P32929      CTH  MQEKDASSQGFLPHFQHFATQAIHVGQDPEQWTSRAVVPPISLSTT...   \n",
              "1      A4D0Y5  C7orf77  MGAERVCTKAPEITQDEAEIYSLTNMEGNIGIKGCEFKSWLFKFYQ...   \n",
              "2      Q49A92  C8orf34  MSSPLASELSELAALRPGFRLSAPHARVAPRAATHARGRGRASHAG...   \n",
              "3      Q9UFW8   CGGBP1  MERFVVTAPPARNRSKTALYVTPLDRVTEFGGELHEDGGKLFCTSC...   \n",
              "4      Q96K31  C8orf76  MDSGCWLFGGEFEDSVFEERPERRSGPPASYCAKLCEPQWFYEETE...   \n",
              "...       ...      ...                                                ...   \n",
              "20406  P49286   MTNR1B  MSENGSFANCCEAGGWAVRPGWSGAGSARPSRTPRPPWVAPALSAV...   \n",
              "20407  P84157    MXRA7  MEAPAELLAALPALATALALLLAWLLVRRGAAASPEPARAPPEPAP...   \n",
              "20408  Q9NP71   MLXIPL  MAGALAGLAAGLQVPRVAPSPDSDSDTDSEDPSLRRSAGGLLRSQV...   \n",
              "20409  Q9BWT6     MND1  MSKKKGLSAEEKRTRMMEIFSETKDVFQLKDLEKIAPKEKGITAMS...   \n",
              "20410  Q8IVL6     P3H3  MLRLLRPLLLLLLLPPPGSPEPPGLTQLSPGAPPQAPDLLYADGLR...   \n",
              "\n",
              "       Tclin  Metal ion binding  Pos reg RNA pol II  Ulcerative colitis  \\\n",
              "0          0                  0                   0                   0   \n",
              "1          0                  0                   0                   0   \n",
              "2          0                  0                   0                   0   \n",
              "3          0                  0                   0                   0   \n",
              "4          0                  0                   0                   0   \n",
              "...      ...                ...                 ...                 ...   \n",
              "20406      1                  0                   0                   0   \n",
              "20407      0                  0                   0                   1   \n",
              "20408      0                  0                   1                   0   \n",
              "20409      0                  0                   0                   0   \n",
              "20410      0                  0                   0                   0   \n",
              "\n",
              "       Liver cancer  \n",
              "0                 0  \n",
              "1                 0  \n",
              "2                 0  \n",
              "3                 0  \n",
              "4                 0  \n",
              "...             ...  \n",
              "20406             0  \n",
              "20407             0  \n",
              "20408             0  \n",
              "20409             0  \n",
              "20410             0  \n",
              "\n",
              "[20386 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ef7ddafc-a4e8-4597-980a-677e91a4e199\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UniProt</th>\n",
              "      <th>Symbol</th>\n",
              "      <th>Sequence</th>\n",
              "      <th>Tclin</th>\n",
              "      <th>Metal ion binding</th>\n",
              "      <th>Pos reg RNA pol II</th>\n",
              "      <th>Ulcerative colitis</th>\n",
              "      <th>Liver cancer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>P32929</td>\n",
              "      <td>CTH</td>\n",
              "      <td>MQEKDASSQGFLPHFQHFATQAIHVGQDPEQWTSRAVVPPISLSTT...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>A4D0Y5</td>\n",
              "      <td>C7orf77</td>\n",
              "      <td>MGAERVCTKAPEITQDEAEIYSLTNMEGNIGIKGCEFKSWLFKFYQ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Q49A92</td>\n",
              "      <td>C8orf34</td>\n",
              "      <td>MSSPLASELSELAALRPGFRLSAPHARVAPRAATHARGRGRASHAG...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Q9UFW8</td>\n",
              "      <td>CGGBP1</td>\n",
              "      <td>MERFVVTAPPARNRSKTALYVTPLDRVTEFGGELHEDGGKLFCTSC...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Q96K31</td>\n",
              "      <td>C8orf76</td>\n",
              "      <td>MDSGCWLFGGEFEDSVFEERPERRSGPPASYCAKLCEPQWFYEETE...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20406</th>\n",
              "      <td>P49286</td>\n",
              "      <td>MTNR1B</td>\n",
              "      <td>MSENGSFANCCEAGGWAVRPGWSGAGSARPSRTPRPPWVAPALSAV...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20407</th>\n",
              "      <td>P84157</td>\n",
              "      <td>MXRA7</td>\n",
              "      <td>MEAPAELLAALPALATALALLLAWLLVRRGAAASPEPARAPPEPAP...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20408</th>\n",
              "      <td>Q9NP71</td>\n",
              "      <td>MLXIPL</td>\n",
              "      <td>MAGALAGLAAGLQVPRVAPSPDSDSDTDSEDPSLRRSAGGLLRSQV...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20409</th>\n",
              "      <td>Q9BWT6</td>\n",
              "      <td>MND1</td>\n",
              "      <td>MSKKKGLSAEEKRTRMMEIFSETKDVFQLKDLEKIAPKEKGITAMS...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20410</th>\n",
              "      <td>Q8IVL6</td>\n",
              "      <td>P3H3</td>\n",
              "      <td>MLRLLRPLLLLLLLPPPGSPEPPGLTQLSPGAPPQAPDLLYADGLR...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>20386 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ef7ddafc-a4e8-4597-980a-677e91a4e199')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ef7ddafc-a4e8-4597-980a-677e91a4e199 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ef7ddafc-a4e8-4597-980a-677e91a4e199');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initializes and fits the tokenizer for amino acid sequences\n",
        "\n",
        "aa_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=True)\n",
        "aa_tokenizer.fit_on_texts(all_proteins['Sequence'])\n",
        "\n",
        "\n",
        "# Initializes the nucleotide sequence tokenizer and provides it with the 61 \n",
        "# codons\n",
        "\n",
        "nt_tokenizer = tf.keras.preprocessing.text.Tokenizer(char_level=False, \n",
        "                                                     lower=False)\n",
        "nt_tokenizer.word_index = {'GCT':1, 'GCC':2, 'GCA':3, 'GCG':4, 'CGT':5, 'CGC':6,\n",
        "                           'CGA':7, 'CGG':8, 'AGA':9, 'AGG':10, 'AAT':11, \n",
        "                           'AAC':12, 'GAT':13, 'GAC':14,'TGT':15, 'TGC':16, \n",
        "                           'CAA':17, 'CAG':18, 'GAA':19, 'GAG':20, 'GGT':21, \n",
        "                           'GGC':22, 'GGA':23, 'GGG':24, 'CAT':25, 'CAC':26, \n",
        "                           'ATT':27, 'ATC':28, 'ATA':29, 'CTT':30, 'CTC':31, \n",
        "                           'CTA':32, 'CTG':33, 'TTA':34, 'TTG':35, 'AAA':36, \n",
        "                           'AAG':37, 'ATG':38, 'TTT':39, 'TTC':40, 'CCT':41, \n",
        "                           'CCC':42, 'CCA':43, 'CCG':44, 'TCT':45, 'TCC':46, \n",
        "                           'TCA':47, 'TCG':48, 'AGT':49, 'AGC':50, 'ACT':51, \n",
        "                           'ACC':52, 'ACA':53, 'ACG':54, 'TGG':55, 'TAT':56, \n",
        "                           'TAC':57, 'GTT':58, 'GTC':59, 'GTA':60, 'GTG':61}"
      ],
      "metadata": {
        "id": "B2bY8lliy2TJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def vanilla_aa_oversample(train_set, test_set, max_len=512):\n",
        "  \"\"\"\n",
        "  Truncates the sequences in the training and test sets, augments the \n",
        "  training set by simple oversampling with replacement, tokenizes and pads the\n",
        "  sequences, and returns the datasets.\n",
        "\n",
        "  Args:\n",
        "    train_set (DataFrame): Pandas dataframe containing the training set\n",
        "    test_set (DataFrame): Pandas dataframe containing the test set\n",
        "    max_len (int): maximum sequence length to truncate to\n",
        "  \n",
        "  Returns:\n",
        "    train_copy (DataFrame): a Pandas dataframe containing the oversampled \n",
        "    training data\n",
        "    test_copy (DataFrame): a Pandas dataframe containing the test data\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  train_copy = train_set.copy()\n",
        "  test_copy = test_set.copy()\n",
        "\n",
        "  train_copy['Sequence'] = train_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "  test_copy['Sequence'] = test_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "\n",
        "  train_pos = train_copy[train_copy['Label'] == 1]\n",
        "  train_neg = train_copy[train_copy['Label'] == 0]\n",
        "\n",
        "  train_pos = train_pos.sample(n=len(train_neg), replace=True)\n",
        "\n",
        "  train_copy = pd.concat([train_pos, train_neg])\n",
        "\n",
        "  train_sequences = aa_tokenizer.texts_to_sequences(train_copy['Sequence'])\n",
        "  test_sequences = aa_tokenizer.texts_to_sequences(test_copy['Sequence'])\n",
        "\n",
        "  train_sequences = tf.keras.utils.pad_sequences(train_sequences,\n",
        "                                                 maxlen=max_len)\n",
        "  test_sequences = tf.keras.utils.pad_sequences(test_sequences,\n",
        "                                                maxlen=max_len)\n",
        "\n",
        "  train_copy['Sequence'] = [seq for seq in train_sequences]\n",
        "  test_copy['Sequence'] = [seq for seq in test_sequences]\n",
        "\n",
        "  return train_copy, test_copy\n",
        "\n",
        "\n",
        "def ala_aa_oversample(train_set, test_set, max_len=512, p_sub=0.05):\n",
        "  \"\"\"\n",
        "  Truncates the sequences in the training and test sets, augments the \n",
        "  training set by oversampling with replacement with alanine substitution of \n",
        "  random amino acids, tokenizes and pads the sequences, and returns the \n",
        "  datasets.\n",
        "\n",
        "  Args:\n",
        "    train_set (DataFrame): Pandas dataframe containing the training set\n",
        "    test_set (DataFrame): Pandas dataframe containing the test set\n",
        "    max_len (int): maximum sequence length to truncate to\n",
        "    p_sub (float): probability of substituting each amino acid with alanine\n",
        "  \n",
        "  Returns:\n",
        "    train_copy (DataFrame): a Pandas dataframe containing the oversampled \n",
        "    training data\n",
        "    test_copy (DataFrame): a Pandas dataframe containing the test data\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  train_copy = train_set.copy()\n",
        "  test_copy = test_set.copy()\n",
        "\n",
        "  train_copy['Sequence'] = train_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "  test_copy['Sequence'] = test_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "\n",
        "  train_pos = train_copy[train_copy['Label'] == 1]\n",
        "  train_neg = train_copy[train_copy['Label'] == 0]\n",
        "\n",
        "  train_pos = train_pos.sample(n=len(train_neg), replace=True)\n",
        "\n",
        "  pos_lists = list(train_pos['Sequence'])\n",
        "\n",
        "  pos_new = []\n",
        "\n",
        "\n",
        "  # Loops through each amino acid in each protein sequence and adds it to a new\n",
        "  # sequence, or replaces with alanine with probability p_sub\n",
        "\n",
        "  for i in range(len(pos_lists)):\n",
        "    changed_seq = \"\"\n",
        "\n",
        "    for j in range(len(pos_lists[i])):\n",
        "      if np.random.uniform() < p_sub:\n",
        "        changed_seq += 'A'\n",
        "      \n",
        "      else:\n",
        "        changed_seq += pos_lists[i][j]\n",
        "\n",
        "    pos_lists[i] = changed_seq\n",
        "\n",
        "  train_pos['Sequence'] = [seq for seq in pos_lists]\n",
        "\n",
        "  train_copy = pd.concat([train_pos, train_neg])\n",
        "\n",
        "  train_sequences = aa_tokenizer.texts_to_sequences(train_copy['Sequence'])\n",
        "  test_sequences = aa_tokenizer.texts_to_sequences(test_copy['Sequence'])\n",
        "\n",
        "  train_sequences = tf.keras.utils.pad_sequences(train_sequences,\n",
        "                                                 maxlen=max_len)\n",
        "  test_sequences = tf.keras.utils.pad_sequences(test_sequences,\n",
        "                                                maxlen=max_len)\n",
        "\n",
        "  train_copy['Sequence'] = [seq for seq in train_sequences]\n",
        "  test_copy['Sequence'] = [seq for seq in test_sequences]\n",
        "\n",
        "  return train_copy, test_copy\n",
        "\n",
        "\n",
        "def dict_aa_oversample(train_set, test_set, max_len=512, p_sub=0.05):\n",
        "  \"\"\"\n",
        "  Truncates the sequences in the training and test sets, augments the \n",
        "  training set by oversampling with replacement with dictionary substitution of \n",
        "  random amino acids, tokenizes and pads the sequences, and returns the \n",
        "  datasets.\n",
        "\n",
        "  Args:\n",
        "    train_set (DataFrame): Pandas dataframe containing the training set\n",
        "    test_set (DataFrame): Pandas dataframe containing the test set\n",
        "    max_len (int): maximum sequence length to truncate to\n",
        "    p_sub (float): probability of substituting each amino acid with a close \n",
        "    equivalent\n",
        "  \n",
        "  Returns:\n",
        "    train_copy (DataFrame): a Pandas dataframe containing the oversampled \n",
        "    training data\n",
        "    test_copy (DataFrame): a Pandas dataframe containing the test data\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  train_copy = train_set.copy()\n",
        "  test_copy = test_set.copy()\n",
        "\n",
        "  train_copy['Sequence'] = train_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "  test_copy['Sequence'] = test_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "\n",
        "  train_pos = train_copy[train_copy['Label'] == 1]\n",
        "  train_neg = train_copy[train_copy['Label'] == 0]\n",
        "\n",
        "  train_pos = train_pos.sample(n=len(train_neg), replace=True)\n",
        "\n",
        "  pos_lists = list(train_pos['Sequence'])\n",
        "\n",
        "  pos_new = []\n",
        "\n",
        "  aa_sub_dict = {'A':'V', 'S':'T', 'F':'Y', 'K':'R', 'C':'M', 'D':'E', 'N':'Q', \n",
        "            'V':'I', 'V':'A', 'T':'S', 'Y':'F', 'R':'K', 'M':'C', 'E':'D', \n",
        "            'Q':'N', 'I':'V'}\n",
        "\n",
        "  # Loops through each amino acid in each protein sequence and adds it to a new\n",
        "  # sequence, or replaces with a similar amino acid via aa_sub_dict with \n",
        "  # probability p_sub\n",
        "\n",
        "  for i in range(len(pos_lists)):\n",
        "    changed_seq = \"\"\n",
        "\n",
        "    for j in range(len(pos_lists[i])):\n",
        "      if np.random.uniform() < p_sub and pos_lists[i][j] in aa_sub_dict:\n",
        "        changed_seq += aa_sub_dict[pos_lists[i][j]]\n",
        "      \n",
        "      else:\n",
        "        changed_seq += pos_lists[i][j]\n",
        "\n",
        "    pos_lists[i] = changed_seq\n",
        "\n",
        "  train_pos['Sequence'] = [seq for seq in pos_lists]\n",
        "\n",
        "  train_copy = pd.concat([train_pos, train_neg])\n",
        "\n",
        "  train_sequences = aa_tokenizer.texts_to_sequences(train_copy['Sequence'])\n",
        "  test_sequences = aa_tokenizer.texts_to_sequences(test_copy['Sequence'])\n",
        "\n",
        "  train_sequences = tf.keras.utils.pad_sequences(train_sequences,\n",
        "                                                 maxlen=max_len)\n",
        "  test_sequences = tf.keras.utils.pad_sequences(test_sequences,\n",
        "                                                maxlen=max_len)\n",
        "\n",
        "  train_copy['Sequence'] = [seq for seq in train_sequences]\n",
        "  test_copy['Sequence'] = [seq for seq in test_sequences]\n",
        "\n",
        "  return train_copy, test_copy\n",
        "\n",
        "\n",
        "def aa_to_nt(seqs):\n",
        "  \"\"\"\n",
        "  Takes a set of amino acid sequences and replaces each randomly with one of its\n",
        "  corresponding nucleotide codons.\n",
        "\n",
        "  Args:\n",
        "    seqs (DataFrame): Pandas dataframe containing the sequences to be \n",
        "    substituted with nucleotide codons\n",
        "  \n",
        "  Returns:\n",
        "    seq_lists (list): a list containing the new sequences as a list of strings,\n",
        "    each string representing a codon\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  seq_lists = list(seqs)\n",
        "\n",
        "  seqs_new = []\n",
        "\n",
        "  nt_sub_dict = {\n",
        "        'A': ['GCT ', 'GCC ', 'GCA ', 'GCG '],\n",
        "        'R': ['CGT ', 'CGC ', 'CGA ', 'CGG ', 'AGA ', 'AGG '],\n",
        "        'N': ['AAT ', 'AAC '],\n",
        "        'D': ['GAT ', 'GAC '],\n",
        "        'C': ['TGT ', 'TGC '],\n",
        "        'Q': ['CAA ', 'CAG '],\n",
        "        'E': ['GAA ', 'GAG '],\n",
        "        'G': ['GGT ', 'GGC ', 'GGA ', 'GGG '],\n",
        "        'H': ['CAT ', 'CAC '],\n",
        "        'I': ['ATT ', 'ATC ', 'ATA '],\n",
        "        'L': ['CTT ', 'CTC ', 'CTA ', 'CTG ', 'TTA ', 'TTG '],\n",
        "        'K': ['AAA ', 'AAG '],\n",
        "        'M': ['ATG '],\n",
        "        'F': ['TTT ', 'TTC '],\n",
        "        'P': ['CCT ', 'CCC ', 'CCA ', 'CCG '],\n",
        "        'S': ['TCT ', 'TCC ', 'TCA ', 'TCG ', 'AGT ', 'AGC '],\n",
        "        'T': ['ACT ', 'ACC ', 'ACA ', 'ACG '],\n",
        "        'W': ['TGG '],\n",
        "        'Y': ['TAT ', 'TAC '],\n",
        "        'V': ['GTT ', 'GTC ', 'GTA ', 'GTG ']}\n",
        "\n",
        "  # Loops through each amino acid in each protein sequence and replaces it with\n",
        "  # a randomly chosen codon which codes for it from nt_sub_dict\n",
        "\n",
        "  for i in range(len(seq_lists)):\n",
        "    changed_seq = \"\"\n",
        "\n",
        "    for j in range(len(seq_lists[i])):\n",
        "      codon_index = np.random.randint(len(nt_sub_dict[seq_lists[i][j]]))\n",
        "\n",
        "      codon = nt_sub_dict[seq_lists[i][j]][codon_index]\n",
        "\n",
        "      changed_seq += codon\n",
        "      \n",
        "    seq_lists[i] = changed_seq\n",
        "  \n",
        "  return seq_lists\n",
        "\n",
        "\n",
        "def nt_oversample(train_set, test_set, max_len=512):\n",
        "  \"\"\"\n",
        "  Truncates the sequences in the training and test sets, converts amino acids\n",
        "  randomly to corresponding nucleotide codons while oversampling the training\n",
        "  set, tokenizes and pads the sequences, and returns the datasets.\n",
        "\n",
        "  Args:\n",
        "    train_set (DataFrame): Pandas dataframe containing the training set\n",
        "    test_set (DataFrame): Pandas dataframe containing the test set\n",
        "    max_len (int): maximum sequence length to truncate to\n",
        "    p_sub (float): probability of substituting each amino acid with a close \n",
        "    equivalent\n",
        "  \n",
        "  Returns:\n",
        "    train_copy (DataFrame): a Pandas dataframe containing the oversampled \n",
        "    training data\n",
        "    test_copy (DataFrame): a Pandas dataframe containing the test data\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  train_copy = train_set.copy()\n",
        "  test_copy = test_set.copy()\n",
        "\n",
        "  train_copy['Sequence'] = train_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "  test_copy['Sequence'] = test_copy['Sequence'].apply(lambda x: x[-max_len:])\n",
        "\n",
        "  train_pos = train_copy[train_copy['Label'] == 1]\n",
        "  train_neg = train_copy[train_copy['Label'] == 0].copy()\n",
        "\n",
        "  train_pos = train_pos.sample(n=len(train_neg), replace=True)\n",
        "\n",
        "  train_pos['Sequence'] = [seq for seq in aa_to_nt(train_pos['Sequence'])]\n",
        "\n",
        "  train_neg['Sequence'] = [seq for seq in aa_to_nt(train_neg['Sequence'])]\n",
        "\n",
        "  train_copy = pd.concat([train_pos, train_neg])\n",
        "\n",
        "  test_copy['Sequence'] = [seq for seq in aa_to_nt(test_copy['Sequence'])]\n",
        "\n",
        "  train_sequences = nt_tokenizer.texts_to_sequences(train_copy['Sequence'])\n",
        "  test_sequences = nt_tokenizer.texts_to_sequences(test_copy['Sequence'])\n",
        "\n",
        "  train_sequences = tf.keras.utils.pad_sequences(train_sequences,\n",
        "                                                 maxlen=max_len)\n",
        "  test_sequences = tf.keras.utils.pad_sequences(test_sequences,\n",
        "                                                maxlen=max_len)\n",
        "\n",
        "  train_copy['Sequence'] = [seq for seq in train_sequences]\n",
        "  test_copy['Sequence'] = [seq for seq in test_sequences]\n",
        "\n",
        "  return train_copy, test_copy"
      ],
      "metadata": {
        "id": "m6pJqv14yMr3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "l2_val = 0.001\n",
        "\n",
        "def make_lstm_aa():\n",
        "  \"\"\"\n",
        "  Initializes and returns a bidirectional LSTM model.\n",
        "\n",
        "  Args:\n",
        "    none\n",
        "  \n",
        "  Returns:\n",
        "    model (keras model): the initialized model.\n",
        "    \n",
        "  \"\"\"\n",
        "  l2 = tf.keras.regularizers.L2(l2=l2_val)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding(22, 16, input_length=512, mask_zero=True),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(16, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(32, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(64, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(128, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128)),\n",
        "      \n",
        "      tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=l2),\n",
        "      \n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2)\n",
        "  ])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "def make_conv_aa():\n",
        "  \"\"\"\n",
        "  Initializes and returns a 1D sequence convolutional model.\n",
        "\n",
        "  Args:\n",
        "    none\n",
        "  \n",
        "  Returns:\n",
        "    model (keras model): the initialized model.\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  l2 = tf.keras.regularizers.L2(l2=l2_val)\n",
        "\n",
        "  model = tf.keras.models.Sequential([\n",
        "      tf.keras.layers.Embedding(22, 16, input_length=512, mask_zero=True),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(16, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(32, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(64, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "      \n",
        "      tf.keras.layers.Conv1D(128, 3, activation='relu', kernel_regularizer=l2),\n",
        "      tf.keras.layers.MaxPool1D(2),\n",
        "\n",
        "      tf.keras.layers.Flatten(),\n",
        "            \n",
        "      tf.keras.layers.Dense(2048, activation='relu', kernel_regularizer=l2),\n",
        "      \n",
        "      tf.keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=l2)\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "N0cozjHQMc3O"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_models(dataset, aug_function, model_type):\n",
        "  \"\"\"\n",
        "  <>\n",
        "\n",
        "  Args:\n",
        "    dataset (DataFrame): the dataset of protein sequences and labels\n",
        "    aug_function (function): the augmentation function used to add training data\n",
        "    model_type (str): the type of model to be used\n",
        "  \n",
        "  Returns:\n",
        "    accuracies (list): the accuracy values for each of the 5 folds\n",
        "    aucs (list): the AUC values for each of the five folds\n",
        "    \n",
        "  \"\"\"\n",
        "\n",
        "  n_splits = 5\n",
        "\n",
        "\n",
        "  # dataset_sample_frac is the fraction of the daataset which is retained when\n",
        "  # it is randomly undersampled to create sampled_dataset. This is done to save\n",
        "  # computational resources\n",
        "\n",
        "  dataset_sample_frac = 0.25\n",
        "  splits = KFold(n_splits=n_splits)\n",
        "\n",
        "  accuracies = []\n",
        "  aucs = []\n",
        "\n",
        "  \n",
        "  # Randomly undersamples the dataset\n",
        "\n",
        "  sampled_dataset = dataset.sample(frac=dataset_sample_frac)\n",
        "\n",
        "  \n",
        "  # Splits the dataset into n_splits parts and fits a model on each\n",
        "\n",
        "  for i, (train_index, test_index) in enumerate(splits.split(sampled_dataset)):\n",
        "    train_set = sampled_dataset.iloc[train_index]\n",
        "    test_set = sampled_dataset.iloc[test_index]\n",
        "\n",
        "    train_aug, test_aug = aug_function(train_set, test_set)\n",
        "\n",
        "    train_features = np.vstack(list(train_aug['Sequence']))\n",
        "    test_features = np.vstack(list(test_aug['Sequence']))\n",
        "\n",
        "    train_labels = train_aug['Label']\n",
        "    test_labels = test_aug['Label']\n",
        "\n",
        "    if model_type == 'lstm':\n",
        "      model = make_lstm_aa()\n",
        "    \n",
        "    elif model_type == 'conv':\n",
        "      model = make_conv_aa()\n",
        "\n",
        "    optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "\n",
        "    callbacks = [tf.keras.callbacks.EarlyStopping(patience=2, \n",
        "                                                  restore_best_weights=True\n",
        "                                                  )]\n",
        "\n",
        "    model.compile(loss='bce', \n",
        "                  optimizer=optimizer, \n",
        "                  metrics=['accuracy', tf.keras.metrics.AUC()]\n",
        "                  )\n",
        "\n",
        "    model.fit(train_features, \n",
        "              train_labels, \n",
        "              validation_data=[test_features, test_labels], \n",
        "              callbacks=callbacks, \n",
        "              epochs=50,\n",
        "              verbose=0\n",
        "              )\n",
        "\n",
        "    probs = model.predict(test_features)\n",
        "\n",
        "    accuracies.append(accuracy_score(test_labels, np.round(probs)))\n",
        "    aucs.append(roc_auc_score(test_labels, probs))\n",
        "\n",
        "  return accuracies, aucs"
      ],
      "metadata": {
        "id": "adWvp_Eyf4uB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example of how the fit_models function is used to generate accuracy and AUC\n",
        "# scores for each of 5 folds\n",
        "\n",
        "acc, auc = fit_models(metal_ion_set, dict_aa_oversample, 'conv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKCjh7gJj7Su",
        "outputId": "cbac825a-f8c6-4a64-dc9a-222666b0614c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 4ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 2ms/step\n",
            "32/32 [==============================] - 0s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hn22FUUZAWbH",
        "outputId": "d7127b04-a138-4922-fc34-bd32926902ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.8578431372549019,\n",
              " 0.873405299313052,\n",
              " 0.8675171736997056,\n",
              " 0.7870461236506379,\n",
              " 0.8547595682041217]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wt-1Sx_yAXbA",
        "outputId": "d8fa04db-2619-4d4b-d99d-8fc1fadae5a1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7819880119880119,\n",
              " 0.7281624036727332,\n",
              " 0.7299328859060403,\n",
              " 0.7657141917123165,\n",
              " 0.7948425334535884]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}